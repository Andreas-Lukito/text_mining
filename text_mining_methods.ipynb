{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61ec45c",
   "metadata": {},
   "source": [
    "# Text Mining\n",
    "\n",
    "In this project we would explore the methods of preprocessing text which includes:\n",
    "- BOW (Bag-of-Words)\n",
    "- CBOW\n",
    "- TF-IDF\n",
    "- Word2Vec\n",
    "- GloVe\n",
    "- FastText\n",
    "- OneHotEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13d5b7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29baadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Text preprocessing Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer # or LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
    "from sklearn.feature_extraction.text  import CountVectorizer\n",
    "\n",
    "# Preprocessing Libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd39598",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d00b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_path = \"./train_data.csv\"\n",
    "text_data = pd.read_csv(text_data_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "490a8cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Here are Thursday's biggest analyst calls: App...      0\n",
       "1  Buy Las Vegas Sands as travel to Singapore bui...      0\n",
       "2  Piper Sandler downgrades DocuSign to sell, cit...      0\n",
       "3  Analysts react to Tesla's latest earnings, bre...      0\n",
       "4  Netflix and its peers are set for a ‘return to...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ef7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8d052",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8cf0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str, language: str, tokenize: bool = False, remove_stop_words: bool = False, stem_words: bool = False):\n",
    "    \"\"\"\n",
    "    This function is to clean the text from stopwords, punctuation and return a clean text for further analysis\n",
    "\n",
    "    Args:\n",
    "        text (str):\n",
    "            The dataframe containing the text data\n",
    "        \n",
    "        language (str):\n",
    "            This are the available languages:\n",
    "            - \"catalan\": \"ca\"\n",
    "            - \"czech\": \"cs\"\n",
    "            - \"german\": \"de\"\n",
    "            - \"greek\": \"el\"mlaskjdlj\n",
    "            - \"english\": \"en\"\n",
    "            - \"spanish\": \"es\"\n",
    "            - \"finnish\": \"fi\"\n",
    "            - \"french\": \"fr\"\n",
    "            - \"hungarian\": \"hu\"\n",
    "            - \"icelandic\": \"is\"\n",
    "            - \"italian\": \"it\"\n",
    "            - \"latvian\": \"lv\"\n",
    "            - \"dutch\": \"nl\"\n",
    "            - \"polish\": \"pl\"\n",
    "            - \"portuguese\": \"pt\"\n",
    "            - \"romanian\": \"ro\"\n",
    "            - \"russian\": \"ru\"\n",
    "            - \"slovak\": \"sk\"\n",
    "            - \"slovenian\": \"sl\"\n",
    "            - \"swedish\": \"sv\"\n",
    "            - \"tamil\": \"ta\"\n",
    "        \n",
    "        tokenize (bool):\n",
    "            True = return tokenized data\n",
    "            False = return untokenized data\n",
    "        \n",
    "        remove_stop_words (bool):\n",
    "            True = remove stop words\n",
    "            False = do not remove stop words\n",
    "\n",
    "        stem_words (bool):\n",
    "            True = get the base words (i.e. spraying -> spray)\n",
    "            False = leave the words as is\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(language))\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s)]\n",
    "    \n",
    "    def remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        pattern = re.compile(f\"[{re.escape(characters)}]\")\n",
    "        return pattern.sub(\"\", text)\n",
    "\n",
    "    def stem_text(tokens):\n",
    "        return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    def remove_stopwords_func(tokens):\n",
    "        return [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # Clean process\n",
    "    text = text.strip().lower()                          # lowercase + trim\n",
    "    text = remove_special_characters(text)               # remove punctuation\n",
    "    tokens = tokenize_text(text)                         # tokenize words\n",
    "\n",
    "    if remove_stop_words:\n",
    "        tokens = remove_stopwords_func(tokens)           # remove stopwords\n",
    "        \n",
    "    if stem_words:\n",
    "        tokens = stem_text(tokens)                       # stemming\n",
    "\n",
    "    if tokenize:\n",
    "        return tokens                                    # return as tokens\n",
    "    else:\n",
    "        return \" \".join(tokens)                          # return as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5cfc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love smell freshly brewed coffee morning\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "sample = \"I love the smell of freshly brewed coffee in the morning!\"\n",
    "cleaned = clean_text(sample, language=\"english\", remove_stop_words=True, tokenize=False)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0986989a",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "689b78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.20\n",
    "val_size = 0.10\n",
    "\n",
    "# Splitting the data into train and temp (which will be further split into validation and test)\n",
    "train_df, test_df = train_test_split(text_data, test_size=test_size, stratify=text_data['label'], random_state=42) #stratify is used to ensure that the same proportion of each class is present in both the training and test sets\n",
    "\n",
    "# Splitting train into validation and test sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=val_size, stratify=train_df['label'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4539d32",
   "metadata": {},
   "source": [
    "## Text Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3841ab",
   "metadata": {},
   "source": [
    "### Bag-of-Words\n",
    "\n",
    "Briefly, the bag-of-words preprocessing method only counts the occurence of each word and does not care about the ordering of the words.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Both of these sentences become almost the same for BoW:\n",
    "\n",
    "- “Coffee is life”\n",
    "- “Life is coffee”\n",
    "\n",
    "BoW doesn’t care that the word order is swapped — it just notes that both have “coffee”, “is”, and “life”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee87bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_BOW:  (12232, 33542)\n",
      "train_Vocab:  ['00' '000' '000th' ... 'åkerström' 'є0' 'є1']\n",
      "\n",
      "test_BOW:  (3398, 33542)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "x_train_BOW = vectorizer.fit_transform(train_df[\"text\"])\n",
    "y_train = train_df[\"label\"]\n",
    "train_vocab = vectorizer.get_feature_names_out()\n",
    "print (\"train_BOW: \", x_train_BOW.shape)\n",
    "print (\"train_Vocab: \", train_vocab)\n",
    "print()\n",
    "\n",
    "x_test_BOW = vectorizer.transform(test_df[\"text\"])\n",
    "y_test = test_df[\"label\"]\n",
    "print(\"test_BOW: \", x_test_BOW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008052d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i_guess_thats_all-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
