{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61ec45c",
   "metadata": {},
   "source": [
    "# Text Mining\n",
    "\n",
    "In this project we would explore the methods of preprocessing text which includes:\n",
    "- Bag-of-Words\n",
    "- TF-IDF\n",
    "- Word2Vec\n",
    "- GloVe\n",
    "- FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce13d5b7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29baadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Text preprocessing Libraries\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer # or LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd39598",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d00b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_path = \"./train_data.csv\"\n",
    "text_data = pd.read_csv(text_data_path, sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490a8cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: App...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Here are Thursday's biggest analyst calls: App...      0\n",
       "1  Buy Las Vegas Sands as travel to Singapore bui...      0\n",
       "2  Piper Sandler downgrades DocuSign to sell, cit...      0\n",
       "3  Analysts react to Tesla's latest earnings, bre...      0\n",
       "4  Netflix and its peers are set for a ‘return to...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ef7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8d052",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8cf0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str, language: str, tokenize: bool = False, remove_stop_words: bool = False, stem_words: bool = False):\n",
    "    \"\"\"\n",
    "    This function is to clean the text from stopwords, punctuation and return a clean text for further analysis\n",
    "\n",
    "    Args:\n",
    "        text (str):\n",
    "            The dataframe containing the text data\n",
    "        \n",
    "        language (str):\n",
    "            This are the available languages:\n",
    "            - \"catalan\": \"ca\"\n",
    "            - \"czech\": \"cs\"\n",
    "            - \"german\": \"de\"\n",
    "            - \"greek\": \"el\"mlaskjdlj\n",
    "            - \"english\": \"en\"\n",
    "            - \"spanish\": \"es\"\n",
    "            - \"finnish\": \"fi\"\n",
    "            - \"french\": \"fr\"\n",
    "            - \"hungarian\": \"hu\"\n",
    "            - \"icelandic\": \"is\"\n",
    "            - \"italian\": \"it\"\n",
    "            - \"latvian\": \"lv\"\n",
    "            - \"dutch\": \"nl\"\n",
    "            - \"polish\": \"pl\"\n",
    "            - \"portuguese\": \"pt\"\n",
    "            - \"romanian\": \"ro\"\n",
    "            - \"russian\": \"ru\"\n",
    "            - \"slovak\": \"sk\"\n",
    "            - \"slovenian\": \"sl\"\n",
    "            - \"swedish\": \"sv\"\n",
    "            - \"tamil\": \"ta\"\n",
    "        \n",
    "        tokenize (bool):\n",
    "            True = return tokenized data\n",
    "            False = return untokenized data\n",
    "        \n",
    "        remove_stop_words (bool):\n",
    "            True = remove stop words\n",
    "            False = do not remove stop words\n",
    "\n",
    "        stem_words (bool):\n",
    "            True = get the base words (i.e. spraying -> spray)\n",
    "            False = leave the words as is\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(language))\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s)]\n",
    "    \n",
    "    def remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        pattern = re.compile(f\"[{re.escape(characters)}]\")\n",
    "        return pattern.sub(\"\", text)\n",
    "\n",
    "    def stem_text(tokens):\n",
    "        return [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    def remove_stopwords_func(tokens):\n",
    "        return [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # Clean process\n",
    "    text = text.strip().lower()                          # lowercase + trim\n",
    "    text = remove_special_characters(text)               # remove punctuation\n",
    "    tokens = tokenize_text(text)                         # tokenize words\n",
    "\n",
    "    if remove_stop_words:\n",
    "        tokens = remove_stopwords_func(tokens)           # remove stopwords\n",
    "        \n",
    "    if stem_words:\n",
    "        tokens = stem_text(tokens)                       # stemming\n",
    "\n",
    "    if tokenize:\n",
    "        return tokens                                    # return as tokens\n",
    "    else:\n",
    "        return \" \".join(tokens)                          # return as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cfc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the smell of freshly brewed coffee in the morning\n"
     ]
    }
   ],
   "source": [
    "sample = \"I love the smell of freshly brewed coffee in the morning!\"\n",
    "cleaned = clean_text(sample, language=\"english\", tokenize=False)\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4539d32",
   "metadata": {},
   "source": [
    "## Text Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3841ab",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87bc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i_guess_thats_all-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
